{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T22:18:33.231768Z",
     "start_time": "2025-04-25T22:18:32.011170Z"
    }
   },
   "source": [
    "from os.path import split\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T00:07:45.916277Z",
     "start_time": "2025-04-26T00:06:23.519430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((32, 32)),  # Resize images to 32x32 pixels\n",
    "    torchvision.transforms.ToTensor(),        # Convert images to PyTorch tensors\n",
    "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,))  # Normalize with mean=0.5, std=0.5\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.Food101(\n",
    "    root='/home/kami/Documents/datasets/',\n",
    "    split='train',\n",
    "    download=False,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "a = 0\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch shape: {images.shape}\")  # Should be [64, 1, 32, 32] (batch, channels, height, width)\n",
    "    print(f\"Labels shape: {labels.shape}\")  # Should be [64]\n",
    "    print(f\"Image tensor min: {images.min()}, max: {images.max()}\")  # Check normalization\n",
    "    break  # Only print the first batch\n",
    "\n",
    "print(a)\n"
   ],
   "id": "9cb147db82a3dc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1184\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T00:08:15.230716Z",
     "start_time": "2025-04-26T00:08:15.225349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"LeNet-5 convolutional neural network for MNIST classification.\"\"\"\n",
    "    def __init__(self, num_classes=10 , in_channels=1):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=0)  # Input: 1x32x32, Output: 6x28x28\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)  # Input: 6x14x14, Output: 16x10x10\n",
    "        # Pooling layer (used twice)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)  # Downsample by 2\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Input: 16x5x5 (after pooling), Output: 120\n",
    "        self.fc2 = nn.Linear(120, 84)          # Output: 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)           # Output: 10 (MNIST classes)\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the LeNet-5 network.\"\"\"\n",
    "        x = self.relu(self.conv1(x))      # Conv1 -> ReLU\n",
    "        x = self.pool(x)                  # Pool (28x28 -> 14x14)\n",
    "        x = self.relu(self.conv2(x))      # Conv2 -> ReLU\n",
    "        x = self.pool(x)                  # Pool (10x10 -> 5x5)\n",
    "        x = x.view(-1, 16 * 5 * 5)       # Flatten for FC layers\n",
    "        x = self.relu(self.fc1(x))        # FC1 -> ReLU\n",
    "        x = self.relu(self.fc2(x))        # FC2 -> ReLU\n",
    "        x = self.fc3(x)                   # FC3 (no activation, logits for classification)\n",
    "        return x\n"
   ],
   "id": "63a3fe9e4ef8d32e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T00:09:46.397583Z",
     "start_time": "2025-04-26T00:08:25.454694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = torch.device('cpu')\n",
    "model = LeNet5(num_classes=101, in_channels=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Combines log softmax and NLL loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)  # Adam with learning rate 1e-3\n",
    "\n",
    "st = time.time()\n",
    "# Train for 10 epochs\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    batch_index = 0\n",
    "    for images, labels in train_loader:\n",
    "        # Move data to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log loss every 100 batches\n",
    "        batch_index += 1\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f\"Epoch: {epoch} | Batch: {batch_index} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "et = time.time()\n",
    "print(et-st)\n",
    "print(\"Training completed.\")"
   ],
   "id": "8af32df55e46baa5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch: 0 | Batch: 100 | Loss: 4.5355\n",
      "Epoch: 0 | Batch: 200 | Loss: 4.4505\n",
      "Epoch: 0 | Batch: 300 | Loss: 4.3572\n",
      "Epoch: 0 | Batch: 400 | Loss: 4.2442\n",
      "Epoch: 0 | Batch: 500 | Loss: 4.2588\n",
      "Epoch: 0 | Batch: 600 | Loss: 4.1681\n",
      "Epoch: 0 | Batch: 700 | Loss: 4.5575\n",
      "Epoch: 0 | Batch: 800 | Loss: 4.1953\n",
      "Epoch: 0 | Batch: 900 | Loss: 4.2099\n",
      "Epoch: 0 | Batch: 1000 | Loss: 4.2448\n",
      "Epoch: 0 | Batch: 1100 | Loss: 4.1094\n",
      "80.93330240249634\n",
      "Training completed.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1accc5a3767575f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
