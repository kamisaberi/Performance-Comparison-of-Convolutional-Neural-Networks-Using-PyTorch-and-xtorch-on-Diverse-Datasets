{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-03T01:06:19.535629Z",
     "start_time": "2025-08-03T01:06:19.002707Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "# --- Model & Data Parameters (Identical to C++ examples) ---\n",
    "NUM_ITERATIONS = 100\n",
    "WARMUP_ITERATIONS = 20\n",
    "BATCH_SIZE = 128\n",
    "INPUT_C = 3\n",
    "INPUT_H = 64\n",
    "INPUT_W = 64\n",
    "\n",
    "CONV_OUTC = 64\n",
    "KERNEL_H = 5\n",
    "KERNEL_W = 5\n",
    "CONV_PAD = 2\n",
    "CONV_STRIDE = 1\n",
    "\n",
    "POOL_H = 2\n",
    "POOL_W = 2\n",
    "POOL_STRIDE = 2\n",
    "\n",
    "NUM_CLASSES = 1000\n",
    "\n",
    "\n",
    "# Define the CNN model in PyTorch\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Layer 1: Conv -> ReLU -> Pool\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=INPUT_C,\n",
    "            out_channels=CONV_OUTC,\n",
    "            kernel_size=(KERNEL_H, KERNEL_W),\n",
    "            stride=CONV_STRIDE,\n",
    "            padding=CONV_PAD\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(POOL_H, POOL_W),\n",
    "            stride=POOL_STRIDE\n",
    "        )\n",
    "\n",
    "        # Calculate the flattened size after convolution and pooling\n",
    "        # Input: 64x64 -> Conv -> 64x64 -> Pool -> 32x32\n",
    "        # So, flattened features = 64 channels * 32 height * 32 width\n",
    "        flattened_features = CONV_OUTC * (INPUT_H // POOL_STRIDE) * (INPUT_W // POOL_STRIDE)\n",
    "\n",
    "        # Layer 2: Fully Connected (Linear)\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=flattened_features,\n",
    "            out_features=NUM_CLASSES\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward pass logic\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Flatten the tensor for the linear layer, keeping the batch dimension\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Performance Test: CNN with Python/PyTorch ---\")\n",
    "\n",
    "    # 1. Check for CUDA and select the device\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA is not available. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 2. Enable cuDNN benchmarking\n",
    "    # This is CRITICAL for performance. It tells cuDNN to find the fastest\n",
    "    # convolution algorithm for our specific input size.\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"cuDNN benchmark mode: {torch.backends.cudnn.benchmark}\")\n",
    "\n",
    "    # 3. Create the model and move it to the GPU\n",
    "    model = SimpleCNN().to(device)\n",
    "    # Set the model to evaluation mode (disables things like dropout)\n",
    "    model.eval()\n",
    "\n",
    "    # 4. Create fake input data directly on the GPU\n",
    "    # This is equivalent to cudaMalloc + filling with data\n",
    "    input_tensor = torch.randn(BATCH_SIZE, INPUT_C, INPUT_H, INPUT_W, device=device)\n",
    "    print(f\"Batch: {BATCH_SIZE}, Input: {INPUT_C}x{INPUT_H}x{INPUT_W}, Iterations: {NUM_ITERATIONS}\")\n",
    "\n",
    "    # 5. Warm-up phase\n",
    "    # Run the model a few times to let cuDNN select the best algorithms\n",
    "    # and warm up the GPU caches.\n",
    "    print(f\"\\n--- Starting warm-up ({WARMUP_ITERATIONS} iterations) ---\")\n",
    "    with torch.no_grad(): # Disables gradient calculation for inference\n",
    "        for _ in range(WARMUP_ITERATIONS):\n",
    "            _ = model(input_tensor)\n",
    "\n",
    "    # Wait for all GPU work to finish before starting the benchmark\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # 6. Benchmark loop\n",
    "    print(f\"--- Starting benchmark ({NUM_ITERATIONS} iterations) ---\")\n",
    "\n",
    "    # Using CUDA events for the most accurate GPU-side timing\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    start_event.record() # Start the master timer\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(NUM_ITERATIONS):\n",
    "            _ = model(input_tensor)\n",
    "\n",
    "    end_event.record() # Stop the master timer\n",
    "\n",
    "    # Wait for the events to complete\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # Calculate and print the results\n",
    "    total_time_ms = start_event.elapsed_time(end_event)\n",
    "    avg_time_ms = total_time_ms / NUM_ITERATIONS\n",
    "\n",
    "    print(\"\\n--- PyTorch Results ---\")\n",
    "    print(f\"Total time for {NUM_ITERATIONS} iterations: {total_time_ms:.3f} ms\")\n",
    "    print(f\"Average time per forward pass: {avg_time_ms:.3f} ms\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance Test: CNN with Python/PyTorch ---\n",
      "Using device: cuda\n",
      "cuDNN benchmark mode: True\n",
      "Batch: 128, Input: 3x64x64, Iterations: 100\n",
      "\n",
      "--- Starting warm-up (20 iterations) ---\n",
      "--- Starting benchmark (100 iterations) ---\n",
      "\n",
      "--- PyTorch Results ---\n",
      "Total time for 100 iterations: 262.985 ms\n",
      "Average time per forward pass: 2.630 ms\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b5aabbde5fff6ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
