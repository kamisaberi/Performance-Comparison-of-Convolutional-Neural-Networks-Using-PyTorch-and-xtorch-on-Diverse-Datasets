{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T18:15:16.479612Z",
     "start_time": "2025-04-25T18:15:15.934244Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T18:29:56.506512Z",
     "start_time": "2025-04-25T18:29:56.469415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),  # Resize images to 32x32 pixels\n",
    "    torchvision.transforms.ToTensor(),        # Convert images to PyTorch tensors\n",
    "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,))  # Normalize with mean=0.5, std=0.5\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='/home/kami/Documents/datasets/',\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Example: Iterate through one batch to verify the data\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch shape: {images.shape}\")  # Should be [64, 1, 32, 32] (batch, channels, height, width)\n",
    "    print(f\"Labels shape: {labels.shape}\")  # Should be [64]\n",
    "    print(f\"Image tensor min: {images.min()}, max: {images.max()}\")  # Check normalization\n",
    "    break  # Only print the first batch\n",
    "\n",
    "\n"
   ],
   "id": "9cb147db82a3dc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([64, 1, 32, 32])\n",
      "Labels shape: torch.Size([64])\n",
      "Image tensor min: -1.0, max: 1.0\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T18:21:18.823945Z",
     "start_time": "2025-04-25T18:21:18.821756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 10, in_channels = 1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                        nn.BatchNorm2d(64),\n",
    "                        nn.ReLU())\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"1:\",x.size())\n",
    "        x = self.conv1(x)\n",
    "        print(\"2:\",x.size())\n",
    "        x = self.maxpool(x)\n",
    "        print(\"3:\",x.size())\n",
    "        x = self.layer0(x)\n",
    "        print(\"4:\",x.size())\n",
    "        x = self.layer1(x)\n",
    "        print(\"5:\",x.size())\n",
    "        x = self.layer2(x)\n",
    "        print(\"6:\",x.size())\n",
    "        x = self.layer3(x)\n",
    "        print(\"7:\",x.size())\n",
    "        x = self.avgpool(x)\n",
    "        print(\"8:\",x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(\"9:\",x.size())\n",
    "        x = self.fc(x)\n",
    "        print(\"10:\",x.size())\n",
    "\n",
    "        return x"
   ],
   "id": "63a3fe9e4ef8d32e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ResNet(ResidualBlock, [3, 4, 6, 3] ,10 , 1).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay = 0.005, momentum = 0.9)\n",
    "\n",
    "st = time.time()\n",
    "# Train for 10 epochs\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    batch_index = 0\n",
    "    for images, labels in train_loader:\n",
    "        # Move data to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log loss every 100 batches\n",
    "        batch_index += 1\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f\"Epoch: {epoch} | Batch: {batch_index} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "et = time.time()\n",
    "print(et-st)\n",
    "print(\"Training completed.\")"
   ],
   "id": "8af32df55e46baa5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
